{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/capstj/NLP_LAB/blob/main/nlplab_p3_22bd1a660v_3_5_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d62912c",
      "metadata": {
        "id": "6d62912c",
        "outputId": "f972c515-a714-4f08-8c1d-d7569147c29b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: requests in c:\\users\\babag\\anaconda3\\lib\\site-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\babag\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\babag\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\babag\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\babag\\anaconda3\\lib\\site-packages (from requests->wikipedia-api) (2023.11.17)\n",
            "Building wheels for collected packages: wikipedia-api\n",
            "  Building wheel for wikipedia-api (setup.py): started\n",
            "  Building wheel for wikipedia-api (setup.py): finished with status 'done'\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15438 sha256=c33d959013f7f3dc3dce52002b72f704ab01e0c41e265c73485ffcb4fbc68fee\n",
            "  Stored in directory: c:\\users\\babag\\appdata\\local\\pip\\cache\\wheels\\1d\\f8\\07\\0508c38722dcd82ee355e9d85e33c9e9471d4bec0f8ae72de0\n",
            "Successfully built wikipedia-api\n",
            "Installing collected packages: wikipedia-api\n",
            "Successfully installed wikipedia-api-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a26a8845",
      "metadata": {
        "id": "a26a8845",
        "outputId": "db364017-22e4-45fc-9d6a-ee023b5d2797"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\babag\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d79b111b",
      "metadata": {
        "id": "d79b111b"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdb4405",
      "metadata": {
        "id": "0bdb4405"
      },
      "outputs": [],
      "source": [
        "import wikipediaapi # Wikipedia API to fetch text\n",
        "import spacy # NLP library for lemmatization\n",
        "from nltk.stem import PorterStemmer # Stemming module from nltk\n",
        "from nltk.tokenize import word_tokenize # Tokenization module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6392076e",
      "metadata": {
        "id": "6392076e",
        "outputId": "20878ebd-73d0-49e0-a7e5-b0a0003ec63b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keshav Memorial Institute of Technology is a private engineering college in Hyderabad in Telangana, India.\n",
            "It offers B.Tech degrees in computer science and engineering, artificial intelligence and machine learning, data science, and information technology.\n"
          ]
        }
      ],
      "source": [
        "def get_wikipedia_text(page_title):\n",
        "    wiki_wiki = wikipediaapi.Wikipedia(user_agent=\"MyNLPProject/1.0\", language=\"en\")\n",
        "    page = wiki_wiki.page(page_title)\n",
        "    return page.summary if page.exists() else \"\"\n",
        "\n",
        "text = get_wikipedia_text(\"Keshav_Memorial_Institute_of_Technology\")\n",
        "print(text)  # Print the fetched summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9dce05d",
      "metadata": {
        "id": "d9dce05d"
      },
      "outputs": [],
      "source": [
        "tokens = word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1e5ed65",
      "metadata": {
        "id": "d1e5ed65",
        "outputId": "b46db140-4693-41d7-b901-8c28228ff96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text Sample: ['Keshav', 'Memorial', 'Institute', 'of', 'Technology', 'is', 'a', 'private', 'engineering', 'college']\n",
            "Stemmed Words: ['keshav', 'memori', 'institut', 'of', 'technolog', 'is', 'a', 'privat', 'engin', 'colleg']\n",
            "Lemmatized Words: ['Keshav', 'Memorial', 'Institute', 'of', 'Technology', 'be', 'a', 'private', 'engineering', 'college']\n",
            "\n",
            "Performance Analysis:\n",
            "Stemming Execution Time: 0.00100 seconds\n",
            "Lemmatization Execution Time: 0.02700 seconds\n"
          ]
        }
      ],
      "source": [
        "stemmer = PorterStemmer()\n",
        "start_stem = time.time()  # Start timer\n",
        "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
        "end_stem = time.time()  # End timer\n",
        "\n",
        "# Step 3: Apply Lemmatization\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "start_lem = time.time()  # Start timer\n",
        "doc = nlp(\" \".join(tokens))\n",
        "lemmatized_words = [token.lemma_ for token in doc]\n",
        "end_lem = time.time()  # End timer\n",
        "\n",
        "# Step 4: Display Results\n",
        "print(\"Original Text Sample:\", tokens[:10])\n",
        "print(\"Stemmed Words:\", stemmed_words[:10])\n",
        "print(\"Lemmatized Words:\", lemmatized_words[:10])\n",
        "\n",
        "# Step 5: Performance Comparison\n",
        "print(\"\\nPerformance Analysis:\")\n",
        "print(f\"Stemming Execution Time: {end_stem - start_stem:.5f} seconds\")\n",
        "print(f\"Lemmatization Execution Time: {end_lem - start_lem:.5f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad9439a5",
      "metadata": {
        "id": "ad9439a5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}